{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marc Garard\n",
    "# Logistic Regression\n",
    "# 11/9/2018\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    A, A_save, A_new, Z, W, b, m = None, None, None, None, None, None, 0\n",
    "    alpha, dW, db, cost, interations = None, None, None, None, 0\n",
    "    def __init__(self, A, Y, alpha = 0.01, iterations = 100):\n",
    "# add check for shapes\n",
    "        # check for format and assign class variables\n",
    "        self.A, self.Y = self.checkInputs( A, Y )\n",
    "        self.m = (self.A).shape[1]\n",
    "        # normalize the data and initialize hyperparamters\n",
    "        self.A_save = self.A\n",
    "        #self.A = self.meanNormalize( A )\n",
    "        self.W, self.b = self.initializeParameters( (self.A).shape[0] )\n",
    "        self.alpha = alpha\n",
    "        return\n",
    "\n",
    "    def __del__(self):\n",
    "        return\n",
    "\n",
    "    # check for proper input, else default to self\n",
    "    def checkValuesA( self, A, Y, W, b ):\n",
    "        if A is None: A = self.A\n",
    "        if Y is None: Y = self.Y\n",
    "        if W is None: W = self.W\n",
    "        if b is None: b = self.b\n",
    "        return A, Y, W, b\n",
    "\n",
    "    def checkValuesB( self, A, A_new, Y, W, b, alpha ):\n",
    "        if A is None: A = self.A\n",
    "        if A_new is None: A_new = self.A_new\n",
    "        if Y is None: Y = self.Y\n",
    "        if W is None: W = self.W\n",
    "        if b is None: b = self.b\n",
    "        if alpha is None: alpha = self.alpha\n",
    "        return A, A_new, Y, W, b\n",
    "\n",
    "    def initializeParameters(self, dim1, dim2 = 1, seed = 1):\n",
    "        np.random.seed(seed)\n",
    "        return (np.random.randn(dim1*dim2)*0.01).astype(np.float64).reshape(dim2, dim1), np.zeros((1, dim2))\n",
    "\n",
    "    def sigmoid( self, Z ):#\n",
    "        return 1/(1+np.exp(-Z))\n",
    "\n",
    "    # activation function\n",
    "    def activation(self, Z):\n",
    "        return self.sigmoid(Z)\n",
    "\n",
    "    # linear function\n",
    "    def Zf( self, A , W, b ):\n",
    "        self.Z = np.sum(W.T*A, axis = 0) + b\n",
    "        return self.Z\n",
    "\n",
    "    def costf(self, A_new, Y):\n",
    "        m = A_new.shape[1]\n",
    "        self.cost = np.sum( -np.multiply( np.log(A_new),Y ) + np.multiply(np.log(1-A_new),(1-Y) ) ) / m\n",
    "        return self.cost\n",
    "\n",
    "    def forwardProp(self, A = None, Y = None, W = None, b = None):\n",
    "        # check for proper input, else default to self\n",
    "        A, Y, W, b = self.checkValuesA( A, Y, W, b )\n",
    "        self.A_new = self.activation(self.Zf( A, W, b ))\n",
    "        self.cost = self.costf( self.A_new, Y )\n",
    "        return self.cost\n",
    "\n",
    "    def meanNormalize(self, A = None ):\n",
    "        if A is None: A = self.A_Save\n",
    "        return ( A - np.mean( A ) ) / ( np.amax( A ) - np.amin( A ) )\n",
    "\n",
    "    def backProp(self, W = None, b = None, A_new = None, A = None, Y = None, alpha = None):\n",
    "        A, A_new, Y, W, b= self.checkValuesB( A, A_new, Y, W, b, alpha )\n",
    "        m = A_new.shape[1]\n",
    "        self.dZ = A_new - Y\n",
    "        self.dW = ( np.sum(A*self.dZ, axis = 1, keepdims = True) / m ).T\n",
    "        self.db = np.sum(self.dZ, axis = 1, keepdims = True) / m\n",
    "        self.W, self.b = self.updateParams( W, b, self.dW, self.db )\n",
    "        return self.dW, self.db\n",
    "\n",
    "    def updateParams( self, W, b, dW, db ):\n",
    "        self.W = W - (self.alpha*dW)\n",
    "        self.b = b - self.alpha*db\n",
    "        return self.W, self.b\n",
    "\n",
    "    def train( self, iterations = None ):\n",
    "        if iterations is None: iterations = 5\n",
    "        for i in range( iterations ):\n",
    "            self.forwardProp()\n",
    "            self.backProp()\n",
    "        return\n",
    "\n",
    "    def trainAccuracy( self ):\n",
    "        sig = self.sigmoid(self.Zf(self.A_save, self.W, self.b))\n",
    "        ls = np.array([1 if i >= 0.5 else 0 for i in sig[0] ])\n",
    "        #print( np.sum(ls==self.Y)/len(self.Y[0])*100,\"%\" )\n",
    "        return np.sum(ls==self.Y)/len(self.Y[0])*100, \"%\"\n",
    "\n",
    "    def optimizeAlpha(self, r = [0.001, .005,0.01, 0.1, 1, 2]):\n",
    "        best, best2 = 10000, 10000\n",
    "        i1, i2 = None, 0\n",
    "        for i, val in enumerate(r):\n",
    "            W = self.W\n",
    "            b = self.b\n",
    "            self.alpha = val\n",
    "            self.train(10)\n",
    "            best2 =self.cost\n",
    "            if ((self.cost < best) and self.cost > 0):\n",
    "                if best < best2:\n",
    "                    best2 = best\n",
    "                    i2 = i1\n",
    "                best = self.cost\n",
    "                i1 = i\n",
    "            self.A = self.A_save\n",
    "            self.W = W\n",
    "            self.b = b\n",
    "        return\n",
    "\n",
    "    def predict( self, X ):\n",
    "        X, Y = self.checkInputs( X )\n",
    "        sig = self.sigmoid(self.Zf(X, self.W, self.b))\n",
    "        return np.array([1 if i >= 0.5 else 0 for i in sig[0] ])\n",
    "\n",
    "    def checkInputs( self, A, Y = [0] ):\n",
    "        if type(A) != 'numpy.ndarray' and type(Y) != 'numpy.ndarray':\n",
    "            A = np.array(A)\n",
    "            Y = np.array(Y).reshape(1, len(Y))\n",
    "        else:\n",
    "            A = A\n",
    "            Y = Y\n",
    "        return A, Y\n",
    "\n",
    "    def setValue( self, key, val ):\n",
    "        if key == 'A': self.A = val\n",
    "        if key == 'A_new': self.A_new = val\n",
    "        if key== 'Y': self.Y = val\n",
    "        if key == 'W': self.W = val\n",
    "        if key == 'b': self.b = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost =  0.007038049803198759\n",
      "train accuracy =  (84.61538461538461, '%')\n",
      "\n",
      "test set = [[4.1],[-80]] \n",
      "prediction (0) =  [0]\n",
      "\n",
      "test set = [[3.9],[100]] \n",
      "prediction (1) =  [1]\n"
     ]
    }
   ],
   "source": [
    "X = [[1, 2, 3, 4.1, 5, 6, 3.9, 3.6, 4.5, 3.9, 3.9, 4.1, 4.1 ],[1, 3, 2, 1, 4, 8, -1, -5, 1, 20, -20, 20, -20]]\n",
    "Y = [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
    "alpha = 0.3404\n",
    "a = LogisticRegression(X, Y, alpha)\n",
    "a.train(10000)\n",
    "print( 'cost = ',a.cost )\n",
    "print( 'train accuracy = ', a.trainAccuracy() )\n",
    "# intended limits on detection 0 and 1\n",
    "print( \"\\ntest set = [[4.1],[-80]]\", '\\nprediction (0) = ', a.predict( [[4.1],[-80]] ) )\n",
    "print( \"\\ntest set = [[3.9],[100]]\", '\\nprediction (1) = ', a.predict( [[3.9],[100]] ) )\n",
    "del( a )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
