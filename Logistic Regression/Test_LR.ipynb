{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LogisticRegresssion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-576a240a5a3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 12/16/18 updated to sample against Normal distribution and exponetial distribution to test the logistic regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# and to include contour maps of the training result and to use the optimizeAlpha function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mLogisticRegression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegresssion\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LogisticRegresssion'"
     ]
    }
   ],
   "source": [
    "# Marc Garard\n",
    "# 12/16/18 updated to sample against Normal distribution and exponetial distribution to test the logistic regression\n",
    "# and to include contour maps of the training result and to use the optimizeAlpha function\n",
    "from LogisticRegression import LogisticRegresssion\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats\n",
    "\n",
    "#create data set: X1\n",
    "x_range, y_range = 6, 1\n",
    "X1 = np.random.rand(2,550)\n",
    "X1[0] *= x_range\n",
    "X1[1] *= y_range\n",
    "\n",
    "#create data set: Y1\n",
    "mu, sigma = 3, math.sqrt(1)\n",
    "Y1, Y2 = [0]*len(X1[0]), [0]*len(X1[0])\n",
    "for i in range( len(X1[0]) ):\n",
    "    if X1[1][i] > scipy.stats.norm.pdf(X1[0][i], mu, sigma): Y1[i] = 1\n",
    "    if X1[1][i] > scipy.stats.expon.pdf(X1[0][i], 0, 2): Y2[i] = 1\n",
    "\n",
    "# train the data on two sets: a, b\n",
    "alpha = 0.110\n",
    "a = LogisticRegression(X1, Y1, alpha = alpha)\n",
    "a.optimizeAlpha(np.arange(0.002, 1, 0.002), 100)\n",
    "print('Optimized Alpha for Normal Distribution = ', a.alpha)\n",
    "b = LogisticRegression(X1, Y2, alpha = alpha)\n",
    "b.optimizeAlpha(np.arange(0.002, 1, 0.002), 100)\n",
    "print(\"Optimized Alpha for Exponential Distribution = \", b.alpha)\n",
    "\n",
    "a.train(100000)\n",
    "b.train(100000)\n",
    "print( 'A Train Accuracy: ', a.trainAccuracy() )\n",
    "print( 'B Train Accuracy: ', b.trainAccuracy() )\n",
    "\n",
    "\n",
    "# Set min and max values and give it some padding\n",
    "x_min, x_max = -0.1, x_range + 0.1\n",
    "y_min, y_max = -0.1, y_range + 0.1\n",
    "h = 0.01\n",
    "    \n",
    "# Generate a grid of points with distance h between them\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict the function value for the whole grid\n",
    "Z1 = a.predict([xx.ravel(), yy.ravel()])\n",
    "Z1 = Z1.reshape(xx.shape)\n",
    "Z2 = b.predict([xx.ravel(), yy.ravel()])\n",
    "Z2 = Z2.reshape(xx.shape)\n",
    "\n",
    "# close the objects\n",
    "del(a)\n",
    "del(b)\n",
    "\n",
    "# Plot the contour and training examples\n",
    "plt.contourf(xx, yy, Z1, cmap=plt.cm.Spectral)\n",
    "plt.ylabel('x2')\n",
    "plt.xlabel('x1')\n",
    "xl1 = np.linspace(mu - 3*sigma, mu + 3*sigma, 10000)\n",
    "plt.plot(xl1, scipy.stats.norm.pdf(xl1, mu, sigma), color = 'orange', label = 'Ideal fit Normal Distribution')\n",
    "plt.scatter(X1[0], X1[1], c=Y1, cmap=plt.cm.Spectral)\n",
    "plt.title(\"Logistic Regression on Normal Distribution\")\n",
    "plt.legend(loc=9)\n",
    "plt.show()\n",
    "\n",
    "# Plot the contour and training examples\n",
    "plt.contourf(xx, yy, Z2, cmap=plt.cm.Spectral)\n",
    "plt.ylabel('x2')\n",
    "plt.xlabel('x1')\n",
    "xl2 = np.linspace(0, 6, 10000)\n",
    "plt.plot(xl2, scipy.stats.expon.pdf(xl2, 0, 2), c='orange', label = 'Ideal Fit Exponential Distribution')\n",
    "plt.scatter(X1[0], X1[1], c=Y2, cmap=plt.cm.Spectral)\n",
    "plt.title(\"Logistic Regression on Exponential Distribution\")\n",
    "plt.legend(loc=9)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
